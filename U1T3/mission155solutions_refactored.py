# -*- coding: utf-8 -*-
"""Mission155Solutions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17o4gFGQXtoh9_ZMsPZZm8wFUHQmC4JUL

## Introduction To The Data Set
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
# %matplotlib inline

pd.options.display.max_columns = 99

cols = [
        'symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration',
        'num-of-doors', 'body-style', 'drive-wheels', 'engine-location',
        'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type',
        'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke',
        'compression-rate', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg',
        'price']
cars = pd.read_csv('imports-85.data', names=cols)

cars.head()

# Select only the columns with continuous values from -
#  https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.names
continuous_values_cols = ['normalized-losses', 'wheel-base', 'length', 'width',
                          'height', 'curb-weight', 'engine-size', 'bore',
                          'stroke', 'compression-rate', 'horsepower', 'peak-rpm',
                          'city-mpg', 'highway-mpg', 'price']
numeric_cars = cars[continuous_values_cols]

numeric_cars.head(5)

## Data Cleaning

numeric_cars = numeric_cars.replace('?', np.nan)
numeric_cars.head(5)

numeric_cars = numeric_cars.astype('float')
print(numeric_cars.isnull().sum())

# Because `price` is the column we want to predict,
# let's remove any rows with missing `price` values.
numeric_cars = numeric_cars.dropna(subset=['price'])
numeric_cars.isnull().sum()

# Replace missing values in other columns using column means.
numeric_cars = numeric_cars.fillna(numeric_cars.mean())

# Confirm that there's no more missing values!
print(numeric_cars.isnull().sum())

# Normalize all columnns to range from 0 to 1 except the target column.
price_col = numeric_cars['price']
numeric_cars = (numeric_cars - numeric_cars.min())/(numeric_cars.max() - numeric_cars.min())
numeric_cars['price'] = price_col

"""## Univariate Model"""

def split_dataset(data_frame: pd.DataFrame):
    """ Split dataset into train and test
    Args:
        data_frame (pd.DataFrame): Data set to split into train and test.
    Returns:
        (tuple): The train and test set respectively.
    """
    np.random.seed(1)

    # Randomize order of rows in data frame.
    shuffled_index = np.random.permutation(data_frame.index)
    rand_df = data_frame.reindex(shuffled_index)

    # Divide number of rows in half and round.
    last_train_row = int(len(rand_df) / 2)

    # Select the first half and set as training set.
    # Select the second half and set as test set.
    train = rand_df.iloc[0:last_train_row]
    test = rand_df.iloc[last_train_row:]

    return train, test

def fit_knn(train_dataframe: pd.DataFrame, train_cols: list, target_cols: list,
            n_neighbors=5):
    """ Create and fit a KNN Regressor model
    Args:
        train_dataframe (pd.DataFrame): Train dataset.
        train_cols (list): Columns of train dataset that will be used as
        knn model input.
        target_cols (list): Columns of train dataset that will be used as
        knn model output.
        n_neighbors (Optional[int]): Number of KNN model neighbors.
    Returns:
        (KNeighborsRegressor): Trained model.
    """
    new_knn = KNeighborsRegressor(n_neighbors= n_neighbors)

    # Fit a KNN model using default k value.
    new_knn.fit(train_dataframe[train_cols], train_dataframe[target_cols])

    return new_knn

def rmse(model, test_dataframe: pd.DataFrame, train_cols: list, target_cols: list):
    """ Get the RMSE from a ML model
    Args:
        model (Regressor): Can be any regressor model from Keras or Sklearn.
        test_df (pd.DataFrame): Test dataset.
        train_cols (list): Columns of train dataset that will be used as
        knn model input.
        target_cols (list): Columns of train dataset that will be used as
        knn model output.
    Returns:
        (float): RMSE.
    """
    # Make predictions using model.
    predicted_labels = model.predict(test_dataframe[train_cols])

    # Calculate and return RMSE.
    mse = mean_squared_error(test_dataframe[target_cols], predicted_labels)
    rmse_value = np.sqrt(mse)
    return rmse_value

# Split datasets into train and test data
train_df, test_df = split_dataset(numeric_cars)

rmse_results = {}
target_col = ['price']
train_col_list = list(numeric_cars.columns.drop(target_col))

# For each column (minus `price`), train a model, return RMSE value
# and add to the dictionary `rmse_results`.
for train_col in train_col_list:
    knn = fit_knn(train_df, [train_col], target_col)
    rmse_results[train_col] = rmse(knn, test_df, [train_col], target_col)

# Create a Series object from the dictionary so
# we can easily view the results, sort, etc
rmse_results_series = pd.Series(rmse_results)
print(rmse_results_series.sort_values())

k_values = [1,3,5,7,9]
k_rmse_results = {}

for train_col in train_col_list:
    k_rmses = {}

    for k_neighbors in k_values:
        # Fit model using k nearest neighbors.
        knn = fit_knn(train_df, [train_col], target_col, k_neighbors)
        k_rmses[k_neighbors] = rmse(knn, test_df, [train_col], target_col)

    k_rmse_results[train_col] = k_rmses

print(k_rmse_results)

def plot_results(results: dict, xlabel: str, ylabel: str):
    """ Plot the results of a given model
    Args:
        results (dict(dict)): Stores the results of a given model.
        xlabel (str): X axis label.
        ylabel (str): Y axis label.
    """
    for _, results_dict in results.items():
        keys = list(results_dict.keys())
        values = list(results_dict.values())
        plt.plot(keys, values)
        plt.xlabel(xlabel)
        plt.ylabel(ylabel)
    plt.show()

plot_results(k_rmse_results, 'k value', 'RMSE')

# Compute average RMSE across different `k` values for each feature.
feature_avg_rmse = {}
for k,v in k_rmse_results.items():
    avg_rmse = np.mean(list(v.values()))
    feature_avg_rmse[k] = avg_rmse

series_avg_rmse = pd.Series(feature_avg_rmse)
sorted_series_avg_rmse = series_avg_rmse.sort_values()

print(sorted_series_avg_rmse)

sorted_features = sorted_series_avg_rmse.index

k_rmse_results = {}

for nr_best_feats in range(2,7):
    train_col_list = sorted_features[:nr_best_feats].tolist()
    knn = fit_knn(train_df, train_col_list, target_col, 5)
    k_rmse_results[f"{nr_best_feats} best features"] = rmse(
        knn, test_df, train_col_list, target_col
    )

print(k_rmse_results)

k_rmse_results = {}

for nr_best_feats in range(2,6):
    # Split train/test dataset
    train_col_list = sorted_features[:nr_best_feats].tolist()

    k_rmses = {}
    for k_neighbors in range(1, 25):
        # Fit model using k nearest neighbors.
        knn = fit_knn(train_df, train_col_list, target_col, k_neighbors)
        k_rmses[k_neighbors] = rmse(knn, test_df, train_col_list, target_col)

    k_rmse_results[f"{nr_best_feats} best features"] = k_rmses

print(k_rmse_results)

plot_results(k_rmse_results, "k value", "RMSE")
